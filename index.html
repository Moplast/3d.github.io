<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<script type="text/javascript"
  		src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		<title>3D Spatial Features for Multi-channel Target Speech Separation</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h2 align="center">3D NEURAL BEAMFORMING FOR MULTI-CHANNEL SPEECH SEPARATION AGAINST LOCATION UNCERTAINTY</h2>
											<p><center>Anonymous Authors</center></p>
										</header>
										<p><b>Abstract</b>:
											Multi-channel speech separation using speaker’s directional information has demonstrated significant gains over blind separation. However, it has two limitations.
											First, substantial performance degradation is observed when the coming directions of two sounds are close.
											Second, the result highly relies on the precise estimation of the speaker’s direction.
											To overcome these issues, this paper proposed 3D features and anassociated 3D neural beamformer for speech separation.
											Previous works in this area are extended in two important directions.
											First, the traditional 1D directional beam patterns are generalized to 3D. This enables to extract speech in any target region in the 3D space.
											Thus, speakers in the same direction but with different elevations or distances become separable.
											Second, to handle the speaker location uncertainty, previously proposed spatial feature is extended to a new 3D region feature.
											The proposed feature and model are evaluated under an in-car scenario. Experimental results demonstrated that the proposed 3D region feature and 3D beamformer can achieve comparable performance to that with ground truth speaker location input.									</p>
										<!--
										<ul class="actions">
											<li><a href="#" class="button big">Learn More</a></li>
										</ul>-->
										<div align="center">
										<img src="images/framework.png" style="background-repeat:no-repeat; background-size:contain" width="30%" alt=""  />
										</div>
										
									</div>
									
								</section>

							<section id="3D">
								<header class="major">
									<h2>From 1D to 3D spatial feature</h2>
								</header>
								<div class="posts">
									<article>
										<table cellspacing="50" style="width: 100%" frame=void>											
											<thead>
												<tr>
												<th colspan="4">
													<div class="img">
														<img src="images/sf.jpg" width=1500px></img>
														</div>
												</th>
												</tr>
												<tr border-top:none>
													<td width="100"></td>
													<td width="300"><center>SF based on azimuth</center> </td>
													<td width="300"><center>SF based on azimuth and elevation</center> </td>
													<td width="300"><center>SF based on azimuth, elevation and distance</center> </th>
												</tr>
												<tr border="0px solid">
													<td width="100"></td>
													<td width="300"><center>
														<!--$$d_m (\theta) = \varDelta_m \cos\theta$$</center>-->
														<img src="https://latex.codecogs.com/gif.latex?d_m(\theta)=\varDelta_m\cos\theta">
													</td>
													<td width="300"><center>
														<!--$$d_m (\theta,\phi) = \varDelta_m \cos\theta\cos \phi$$</center>-->
														<img src="https://latex.codecogs.com/gif.latex?d_m (\theta,\phi)=\varDelta_m \cos\theta\cos\phi">
													</td>
													<td width="300">
														<!--<center>$$d_m(\theta,\phi,d_o) =d_{m_1} - d_{m_2}$$</center>
														<center>$$d^2_{m_1}=d^2_{om_1}+d^2_o-2d_{om_1}d_o \cos \alpha$$</center>
														<center>$$\cos\alpha=\cos\theta\cos\phi$$</center>-->
														<center><img src="https://latex.codecogs.com/gif.latex?d_m(\theta,\phi,d_o)=d_{m_1} - d_{m_2}"><br>
														<img src="https://latex.codecogs.com/gif.latex?d^2_{m_1}=d^2_{om_1}+d^2_o-2d_{om_1}d_o\cos\alpha">
														<br>
														<img src="https://latex.codecogs.com/gif.latex?\cos\alpha=\cos\theta\cos\phi">
													</center>
													</td>
												</tr>
											</thead>
										</table>

										<!--<ul class="actions">
											<li><a href="#" class="button">More</a></li>
										</ul>-->
									</article>
								</div>
							</section>

							<!-- Section -->
							<section id="accuracy">
								<header class="major">
									<h2>Effects of location uncertainty</h2>
								</header>

									<div class="centent">
										<p>We report the performances when the spatial features are extracted with deviated azimuth, elevation or distance. </p>
										<p>It can be observed that the 3D spatial feature based on azimuth, elevation and distance is quite sensitive to the localization accuracy,
											compared to other spatial features.
											To alleviate this problem, we have explored some strategies.
											For example, data augmentation such as introducing the error during training (the red line in Azimuth figure).</p>
										<p>
											In this work, we sample some candidate locations in the adjacent 3d regions around the given location (θ,φ,d), and design an attention mechanism to selectively focus on these candidate locations. </p>
									</div>

								<div class="posts">
									<article>
										<table cellspacing="50" style="width: 50%">
											<thead>
												<tr>
													<th><center>Azimuth</center> </th>
													<th><center>Elevation</center> </th>
													<th><center>Distance</center> </th>

												</tr>

											</thead>
											<thead>
												<tr style="border-top:1px solid black">
													<td><img src="images/azimuth.png" width=500px>
													</img></td>

													<td>
										<div class="img">
										<img src="images/elevation.png" width=500px></img>
										</div>
									</td>
									<td>
										<div class="img">
											<img src="images/distance.png" width=500px></img>
											</div>
									</td>

								</thead>
										</table>

										<!--<ul class="actions">
											<li><a href="#" class="button">More</a></li>
										</ul>-->
									</article>
								</div>
							</section>
								

				<!-- Section -->
				<section id="exp">
					<header class="major">
						<h2>Experiments on real-recorded data</h2>
					</header>
							<div class="content">
								<h3>Scenario</h3>
								<p>In order to evaluate our proposed method in real-life applications, we consider a in-car scenario (Figure 1). As shown in Figure 2, there are 4 potential speakers and corresponding regions in a car: the main driver (S1), the co-driver (S2) and two passengers (S3 & S4) sitting in the back. We take the main driver's voice as the target. It can be seen from the top view that the azimuths of the main driver (S1) and the passenger in the back seat (S3) are very close. In this case, it is difficult to distinguish these two speakers with the spatial feature only based on azimuth.
								</p>
								<div class="img" align="center">
									<img style="margin-bottom:50px" src="images/car.png" width=700px></img> 
									<img style="margin-left:100px" src="images/top_view.png" width=700px></img>
								</div>
								
								<div class="text" align="center">
									Fig.1 The detailed information of the car.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
									&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
									Fig.2 4 speakers corresponding to 4 regions in the car.
								</div>
								
							</div>

					
					<div class="content" style="margin-top:50px">
						<h3>Spatial Features</h3>
						<p>We assume that the main driver (as well as other passengers) will be located within a limited region (a 3D box as shown in the figure below, each dot indicates a potential speaker position). The length, width, height and corresponding distance to the microphone array center of this box, are measured according to the specific car. With this information, we can calcalate the expectation center point of the 3D box, and consider the center point as the speaker location. </p>
						<p><b>1D Spatial feature</b>:
							The spatial features based on azimuth that fed into the separation network are always extracted using the fixed center locations of 4 regions (boxes). As shown in the figure, the center locations of four regions are marked with the cross. Only the azimuths of the center points are used to calculate the spatial features. 
						</p>
						<p><b>3D Spatial feature</b>:
							The fixed center locations (including azimuth, elevation and distance) of 4 regions are used to calculate 3D spatial features.
						</p>
						<p><b>3D Region feature</b>:
							We can also sample 8 vertexes of the 3D box to obtain a full spatial view of the whole region. As shown in the figure, 4 (regions) × 9 (spatial positions) spatial features that computed from azimuth, elevation and distance will be extracted and input to the separation model. We design a simple attention mechanism (i.e., weight-and-sum) to make the model selectively focus on useful spatial positions.
						</p>
						<div class="img" align="center">
						<img src="images/side_view.png" style="background-repeat:no-repeat; background-size:contain" width="50%" alt=""/>
						</div>
					</div>

					<div class="features" style="margin-top:50px">
					
						<article>
							<div class="content">
								<h3>Data Preparation</h3>
									<p> In order to train a model to separate the voice of the main driver, we simulate a reverberant noisy dataset. The room size matches that of the car and the microphone array is placed at the car head. We use a dual mic with 11.8cm spacing.</p>
									<p>The simulated dataset contains 90,000 noisy and reverberant N-speaker mixtures for training, validation and testing, where N is randomly selected from [2, 3]. The Multi-channel audio signals are generated by convolving single-channel signals with RIRs simulated by image-source method (ISM).</p>								
							</div>
						</article>
					<article>
						<div class="content">
							<h3>Evaluating </h3>
							<p>
								<b>on real-recorded data</b>: We recorded 25-minute 2-channel overlapped speech data in the specific car, where the AISHELL speech are replayed according to pre-arranged timestamps in each region. Also, the car's player is playing loud music, which is not simulated in the training data. This means there will be a mismatch between the training and testing phase. We calcalate word error rate of each utterance according to the AISHELL transcript. 

								Compared to the unprocessed mixture with WER of <b>108.71%</b>, the WERs for SF based on azimuth and SF based on azimuth, elevation and distance are <b>45.90%</b> and <b>42.74%</b>, respectively. 
							</p>

							<table cellspacing="50" style="width: 80%">
								<thead>
									<tr>
										<th><center>Feature</center> </th>
										<th><center>1D (θ_c)</center> </th>
										<th><center>3D (l_c)</center> </th>
										<th><center>1D (θ_c)</center> </th>
										<th><center>3D (l_c)</center> </th>
										<th><center>3D ({l_c}^9)</center> </th>
									</tr>
								</thead>

								<tbody>
									<tr style="border-top:1px solid black">
										<td><center>Target</center></td>
										<td><center>cRM</center></td>
										<td><center>cRM</center></td>
										<td><center>AN-BF</center></td>
										<td><center>AN-BF</center></td>
										<td><center>AN-BF</center></td>
									</tr>
									<tr style="border-top:1px solid black">
										<td><center>CER (%)</center></td>
										<td><center>108.7</center></td>
										<td><center>45.9</center></td>
										<td><center>42.7</center></td>
										<td><center>27.4</center></td>
										<td><center><b>25.5</b></center></td>
									</tr>
								</tbody>
							</table>
						</div>
					</article>
				</div>


			</section>
		<!-- Section -->
			<section id="rlt">
				<header class="major">
					<h2>Samples on real-recorded data with Echo</h2>
				</header>
				<div class="posts">
					<article>
						<!--a href="#" class="image"><img src="images/pic02.jpg" alt="" /></--a>-->
						<table cellspacing="50" style="width:500">
							<thead>
								<tr>
									<th><center>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mixture&nbsp;(1st&nbsp;channel)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</center> </th>
									<th><center>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GT&nbsp;&nbsp;transcript&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</center></th>
									<th><center>1D (θ_c)</center> </th>
									<th><center>3D (l_c)</center> </th>
									<th><center>1D (θ_c)</center> </th>
									<th><center>3D ({l_c}^9)</center> </th>
								</tr>
							</thead>

							<tbody>
								<tr style="border-top:1px solid black">
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/mix/2_05_400asr_10.94-15.17.wav" ></audio></td>
									<td></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D/2_05_400asr_10.94-15.17.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D/2_05_400asr_10.94-15.17.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D-BF/2_05_400asr_10.94-15.17.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D-BF/2_05_400asr_10.94-15.17.wav" ></audio></td>
								</tr>

								<tr style="border-top:1px solid black;font-size: small" >
									<td> <center>ASR: 下深圳市联合收费号码</center></td>
									<td> <center>深圳今天适合穿外套吗</center></td>
									<td><center>深圳今天<font color="red">是和小</font>外套吗</center></td>
									<td><center>深圳今天适合<font color="red">群</font>外套吗</center></td>
									<td><center>深圳今天适合<font color="red">吃</font>外套吗</center></td>
									<td> <center>深圳今天适合穿外套吗</center></td>
								</tr>

								<tr style="border-top:1px solid black">
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/mix/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D-BF/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D-BF/2_05_400asr_40.68-44.22.wav" ></audio></td>
								</tr>

								<tr style="border-top:1px solid black;font-size: small" >
									<td> <center>ASR: 对这些都没有兴趣</center></td>
									<td> <center>语音可以支持哪些功能</center></td>
									<td><center>语音<font color="red">配置适中</font></center></td>
									<td><center>语音<font color="red">呗</font>支持哪些</center></td>
									<td><center>语音可以支持哪些<font color="red">空的</font></center></td>
									<td> <center>语音可以支持哪些功能</center></td>
								</tr>

								<tr style="border-top:1px solid black">
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/mix/2_05_400asr_747.52-752.21.wav" ></audio></td>
									<td></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D-BF/2_05_400asr_40.68-44.22.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D-BF/2_05_400asr_40.68-44.22.wav" ></audio></td>
								</tr>

								<tr style="border-top:1px solid black;font-size: small" >
									<td> <center>ASR: 中创业难坚持一次发生</center></td>
									<td> <center>我想听邓紫棋唱的穿越火线</center></td>
									<td><center>我想听<font color="red">你</font>唱</center></td>
									<td><center>我想听<font color="red">你</font>唱</center></td>
									<td><center>我想听邓紫琴唱的<font color="red">首先</font></center></td>
									<td> <center>我想听邓紫棋唱的穿越火线</center></td>
								</tr>

								<tr style="border-top:1px solid black">
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/mix/2_05_400asr_963.47-967.15.wav" ></audio></td>
									<td></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D/2_05_400asr_963.47-967.15.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D/2_05_400asr_963.47-967.15.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF1D-BF/2_05_400asr_963.47-967.15.wav" ></audio></td>
									<td><audio controls class="audio-player" preload="metadata" style="width:180px;">
										<source src="audio/AF3D-BF/2_05_400asr_963.47-967.15.wav" ></audio></td>
								</tr>

								<tr style="border-top:1px solid black;font-size: small" >
									<td> <center>ASR: 中创业难坚持一次发生</center></td>
									<td> <center>采菊东篱下的整首古诗</center></td>
									<td><center>采菊东篱下<font color="red">到郑州</font></center></td>
									<td><center>采菊东篱下<font color="red">到郑州</font>古诗</center></td>
									<td><center>采<font color="red">取公</font>篱下的整首古诗</center></td>
									<td> <center>采菊东篱下的整首古诗</center></td>
								</tr>

							</tbody>
						</table>

						<!--<ul class="actions">
							<li><a href="#" class="button">More</a></li>
						</ul>-->
					</article>
				</div>
			</section>

							
					

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
